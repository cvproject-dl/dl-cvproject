{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nlen(os.listdir('./content/gdrive/My Drive/Indcars/test'))","execution_count":4,"outputs":[{"output_type":"execute_result","execution_count":4,"data":{"text/plain":"120"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torchvision\nimport torchvision.models as models\nimport torchvision.transforms as transforms\nfrom torchvision import datasets, transforms, models\n\nfrom tqdm import tqdm\nimport os\nimport PIL.Image as Image\nfrom IPython.display import display,FileLink\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_dir = './content/gdrive/My Drive/Indcars'\ntrain_dir = data_dir + '/train'\ntest_dir = data_dir + '/test'\n","execution_count":6,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#add transforms and load data\ntrain_transforms = transforms.Compose([transforms.Resize((244,244)),\n                                       transforms.RandomRotation(30),\n                                       transforms.RandomHorizontalFlip(),\n                                       transforms.ToTensor(),\n                                       transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n\n\ntest_transforms = transforms.Compose([transforms.Resize((244,244)),\n                                      transforms.CenterCrop(224),\n                                      transforms.ToTensor(),\n                                      transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n\n\n\ntrain_data = datasets.ImageFolder(data_dir + '/train', transform=train_transforms)\ntest_data = datasets.ImageFolder(data_dir + '/test', transform=test_transforms)\n\n\ntrainloader = torch.utils.data.DataLoader(train_data, batch_size=32, shuffle=True,num_workers = 2)\ntestloader = torch.utils.data.DataLoader(test_data, batch_size=32, shuffle=True , num_workers = 2)\n\n","execution_count":7,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train_model(model, criterion, optimizer, scheduler, n_epochs):\n    \n    losses = []\n    accuracies = []\n    test_accuracies = []\n    use_gpu = False\n    \n    # Check to see whether GPU is available\n    if torch.cuda.is_available():\n        use_gpu = True\n        model.cuda()\n    else:\n        model.cpu()\n    print(use_gpu)\n    \n\n    model.train()\n    for epoch in range(n_epochs):\n        running_loss = 0.0\n        running_correct = 0.0\n        for i, data in tqdm(enumerate(trainloader, 0)):\n\n            inputs, labels = data\n            \n            if use_gpu:\n                inputs = inputs.cuda()\n                labels = labels.cuda()\n            \n                \n            optimizer.zero_grad()\n            \n            # forward + backward + optimize\n            outputs = model(inputs)\n            _, predicted = torch.max(outputs.data, 1)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n            \n            # calculate the loss/acc later\n            running_loss += loss.item()\n            running_correct += (labels==predicted).sum().item()\n\n        \n        epoch_loss = running_loss/len(trainloader)\n        epoch_acc = 100/32*running_correct/len(trainloader)\n        print(\"Epoch %s, loss: %.4f, acc: %.4f\" % (epoch+1,epoch_loss, epoch_acc))\n        \n        losses.append(epoch_loss)\n        accuracies.append(epoch_acc)\n        \n        # switch the model to eval mode to evaluate on test data\n        model.eval()\n        test_acc = eval_model(model)\n        test_accuracies.append(test_acc)\n        \n        # re-set the model to train mode after validating\n        model.train()\n        scheduler.step(test_acc)\n    return model, losses, accuracies, test_accuracies\n\n    ","execution_count":8,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def eval_model(model):\n    correct = 0.0\n    total = 0.0\n    with torch.no_grad():\n        for i, data in enumerate(testloader, 0):\n            images, labels = data\n            #images = images.to(device).half() # uncomment for half precision model\n            images = images.to(device)\n            labels = labels.to(device)\n            \n            outputs = model(images)\n            _, predicted = torch.max(outputs.data, 1)\n            \n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n\n    test_acc = 100.0 * correct / total\n    print('Accuracy of the network on the test images: %d %%' % (\n        test_acc))\n    return test_acc","execution_count":9,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = models.resnet34(pretrained=True)\nnum_ftrs = model.fc.in_features\n\nmodel.fc = nn.Linear(num_ftrs, 120)\n\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n\n\n\nlrscheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', patience=3, threshold = 0.9)","execution_count":10,"outputs":[{"output_type":"stream","text":"Downloading: \"https://download.pytorch.org/models/resnet34-333f7ec4.pth\" to /root/.cache/torch/hub/checkpoints/resnet34-333f7ec4.pth\n","name":"stderr"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, max=87306240.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4086a63a3c424cd590b75b7403145037"}},"metadata":{}},{"output_type":"stream","text":"\n","name":"stdout"}]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"model_trained, training_losses, training_accs, test_accs = train_model(model, criterion, optimizer, lrscheduler, n_epochs=20)","execution_count":11,"outputs":[{"output_type":"stream","text":"True\n","name":"stdout"},{"output_type":"stream","text":"221it [01:02,  3.54it/s]","name":"stderr"},{"output_type":"stream","text":"Epoch 1, loss: 4.7261, acc: 2.7291\n","name":"stdout"},{"output_type":"stream","text":"\n","name":"stderr"},{"output_type":"stream","text":"Accuracy of the network on the test images: 7 %\n","name":"stdout"},{"output_type":"stream","text":"221it [01:02,  3.55it/s]","name":"stderr"},{"output_type":"stream","text":"Epoch 2, loss: 4.0091, acc: 16.2472\n","name":"stdout"},{"output_type":"stream","text":"\n","name":"stderr"},{"output_type":"stream","text":"Accuracy of the network on the test images: 21 %\n","name":"stdout"},{"output_type":"stream","text":"221it [01:00,  3.64it/s]","name":"stderr"},{"output_type":"stream","text":"Epoch 3, loss: 3.2795, acc: 29.5956\n","name":"stdout"},{"output_type":"stream","text":"\n","name":"stderr"},{"output_type":"stream","text":"Accuracy of the network on the test images: 32 %\n","name":"stdout"},{"output_type":"stream","text":"221it [01:01,  3.60it/s]","name":"stderr"},{"output_type":"stream","text":"Epoch 4, loss: 2.7249, acc: 41.0916\n","name":"stdout"},{"output_type":"stream","text":"\n","name":"stderr"},{"output_type":"stream","text":"Accuracy of the network on the test images: 40 %\n","name":"stdout"},{"output_type":"stream","text":"221it [01:03,  3.50it/s]","name":"stderr"},{"output_type":"stream","text":"Epoch 5, loss: 2.3212, acc: 48.0062\n","name":"stdout"},{"output_type":"stream","text":"\n","name":"stderr"},{"output_type":"stream","text":"Accuracy of the network on the test images: 45 %\n","name":"stdout"},{"output_type":"stream","text":"221it [01:04,  3.42it/s]","name":"stderr"},{"output_type":"stream","text":"Epoch 6, loss: 2.0078, acc: 54.8077\n","name":"stdout"},{"output_type":"stream","text":"\n","name":"stderr"},{"output_type":"stream","text":"Accuracy of the network on the test images: 48 %\n","name":"stdout"},{"output_type":"stream","text":"221it [01:02,  3.54it/s]","name":"stderr"},{"output_type":"stream","text":"Epoch 7, loss: 1.7485, acc: 59.9830\n","name":"stdout"},{"output_type":"stream","text":"\n","name":"stderr"},{"output_type":"stream","text":"Accuracy of the network on the test images: 50 %\n","name":"stdout"},{"output_type":"stream","text":"221it [01:04,  3.44it/s]","name":"stderr"},{"output_type":"stream","text":"Epoch 8, loss: 1.5450, acc: 63.8292\n","name":"stdout"},{"output_type":"stream","text":"\n","name":"stderr"},{"output_type":"stream","text":"Accuracy of the network on the test images: 53 %\n","name":"stdout"},{"output_type":"stream","text":"221it [01:03,  3.45it/s]","name":"stderr"},{"output_type":"stream","text":"Epoch 9, loss: 1.3562, acc: 68.4672\n","name":"stdout"},{"output_type":"stream","text":"\n","name":"stderr"},{"output_type":"stream","text":"Accuracy of the network on the test images: 54 %\n","name":"stdout"},{"output_type":"stream","text":"221it [01:02,  3.54it/s]","name":"stderr"},{"output_type":"stream","text":"Epoch 10, loss: 1.1699, acc: 73.8546\n","name":"stdout"},{"output_type":"stream","text":"\n","name":"stderr"},{"output_type":"stream","text":"Accuracy of the network on the test images: 57 %\n","name":"stdout"},{"output_type":"stream","text":"221it [01:02,  3.54it/s]","name":"stderr"},{"output_type":"stream","text":"Epoch 11, loss: 1.1136, acc: 75.6363\n","name":"stdout"},{"output_type":"stream","text":"\n","name":"stderr"},{"output_type":"stream","text":"Accuracy of the network on the test images: 57 %\n","name":"stdout"},{"output_type":"stream","text":"221it [01:02,  3.56it/s]","name":"stderr"},{"output_type":"stream","text":"Epoch 12, loss: 1.0899, acc: 76.4423\n","name":"stdout"},{"output_type":"stream","text":"\n","name":"stderr"},{"output_type":"stream","text":"Accuracy of the network on the test images: 58 %\n","name":"stdout"},{"output_type":"stream","text":"221it [01:02,  3.54it/s]","name":"stderr"},{"output_type":"stream","text":"Epoch 13, loss: 1.0633, acc: 77.2766\n","name":"stdout"},{"output_type":"stream","text":"\n","name":"stderr"},{"output_type":"stream","text":"Accuracy of the network on the test images: 58 %\n","name":"stdout"},{"output_type":"stream","text":"221it [01:02,  3.52it/s]","name":"stderr"},{"output_type":"stream","text":"Epoch 14, loss: 1.0433, acc: 78.2240\n","name":"stdout"},{"output_type":"stream","text":"\n","name":"stderr"},{"output_type":"stream","text":"Accuracy of the network on the test images: 57 %\n","name":"stdout"},{"output_type":"stream","text":"221it [01:04,  3.45it/s]","name":"stderr"},{"output_type":"stream","text":"Epoch 15, loss: 1.0397, acc: 78.0402\n","name":"stdout"},{"output_type":"stream","text":"\n","name":"stderr"},{"output_type":"stream","text":"Accuracy of the network on the test images: 58 %\n","name":"stdout"},{"output_type":"stream","text":"221it [01:05,  3.35it/s]","name":"stderr"},{"output_type":"stream","text":"Epoch 16, loss: 1.0284, acc: 78.7330\n","name":"stdout"},{"output_type":"stream","text":"\n","name":"stderr"},{"output_type":"stream","text":"Accuracy of the network on the test images: 58 %\n","name":"stdout"},{"output_type":"stream","text":"221it [01:02,  3.52it/s]","name":"stderr"},{"output_type":"stream","text":"Epoch 17, loss: 1.0404, acc: 78.0402\n","name":"stdout"},{"output_type":"stream","text":"\n","name":"stderr"},{"output_type":"stream","text":"Accuracy of the network on the test images: 57 %\n","name":"stdout"},{"output_type":"stream","text":"221it [01:03,  3.48it/s]","name":"stderr"},{"output_type":"stream","text":"Epoch 18, loss: 1.0342, acc: 77.7715\n","name":"stdout"},{"output_type":"stream","text":"\n","name":"stderr"},{"output_type":"stream","text":"Accuracy of the network on the test images: 58 %\n","name":"stdout"},{"output_type":"stream","text":"221it [01:01,  3.58it/s]","name":"stderr"},{"output_type":"stream","text":"Epoch 19, loss: 1.0243, acc: 78.3512\n","name":"stdout"},{"output_type":"stream","text":"\n","name":"stderr"},{"output_type":"stream","text":"Accuracy of the network on the test images: 57 %\n","name":"stdout"},{"output_type":"stream","text":"221it [01:03,  3.50it/s]","name":"stderr"},{"output_type":"stream","text":"Epoch 20, loss: 1.0293, acc: 78.5492\n","name":"stdout"},{"output_type":"stream","text":"\n","name":"stderr"},{"output_type":"stream","text":"Accuracy of the network on the test images: 58 %\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.cpu()\ntorch.save({'arch': 'resnet34',\n            'state_dict': model.state_dict(), # Holds all the weights and biases\n            },\n            'indresnet34classifier.pth')","execution_count":12,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def find_classes(dir):\n    classes = os.listdir(dir)\n    classes.sort()\n    class_to_idx = {classes[i]: i for i in range(len(classes))}\n    return classes, class_to_idx\nclasses, c_to_idx = find_classes(data_dir+\"/train\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# test the model on random images\n\n\n# switch the model to evaluation mode to make dropout and batch norm work in eval mode\nmodel.eval()\n\n# transforms for the input image\nloader =  transforms.Compose([transforms.Resize((244,244)),\n                                      transforms.CenterCrop(224),\n                                      transforms.ToTensor(),\n                                      transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\nimage = Image.open('./content/gdrive/My Drive/Indcars/test/Maruti Suzuki Omni/64.jpg')\nimage = loader(image).float()\nimage = torch.autograd.Variable(image, requires_grad=True)\nimage = image.unsqueeze(0)\nimage = image.cuda()\noutput = torch.exp(model.forward(image))\ntop_probs, top_labs = output.topk(5)\n\n#conf, predicted = torch.ma(output.data, 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x = 0\nfor labs in top_labs[0]:\n    print(f\"Car: {classes[int(labs)]}\")\n    break\n    x += 1\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}