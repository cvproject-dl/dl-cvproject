{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3.Building a Neural Network.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Aqb4wVhYBFe"
      },
      "source": [
        "# Building a Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oi50BujeXLpU"
      },
      "source": [
        "#From 2.Data notebook\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision import transforms , datasets\n",
        "\n",
        "train = datasets.MNIST(\"\",\n",
        "                       train = True,\n",
        "                       download = True, \n",
        "                       transform = transforms.Compose([transforms.ToTensor()]))\n",
        "test = datasets.MNIST(\"\",\n",
        "                      train = False,\n",
        "                      download = True, \n",
        "                      transform = transforms.Compose([transforms.ToTensor()]))\n",
        "\n",
        "trainset = torch.utils.data.DataLoader(train,batch_size =10,shuffle =True)\n",
        "testset = torch.utils.data.DataLoader(test,batch_size =10,shuffle =True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yEPS88T2YOrA"
      },
      "source": [
        "### Importing pytorch Neural Network Libraries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_rNBwTDoYVI6"
      },
      "source": [
        "\n",
        "\n",
        "*   torch.nn for OOP\n",
        "*   torch.nn.functional for functional programming\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w58G7DkOX4PO"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w-hfzPvtYshv"
      },
      "source": [
        "### Building a Neural Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2PvWjwqKZGfE"
      },
      "source": [
        "* fc - Fully connected layer\n",
        "* Linear :\n",
        "Applies a linear transformation to the incoming data:\n",
        "\n",
        "\n",
        "```\n",
        " y = xA^T + b\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "Args:\n",
        "* in_features: size of each input sample\n",
        "* out_features: size of each output sample\n",
        "* bias: If set to False, the layer will not learn an additive bias. (Default = True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dpPs03QMdQIV"
      },
      "source": [
        "**Relu:**\n",
        "\n",
        "The Rectified Linear Unit is the most commonly used activation function in deep learning models. The function returns 0 if it receives any negative input, but for any positive value  x  it returns that value back. So it can be written as  f(x)=max(0,x) .\n",
        "\n",
        "Graphically it looks like this\n",
        "\n",
        "![relu.png](data:image/png;base64,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)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "83HYoPnSYN8C"
      },
      "source": [
        "class Net(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    \"\"\"\n",
        "    for every fully connected layer, we need three layers of 64 neurons for\n",
        "    hidden layers , so the output is 64\n",
        "    \"\"\"\n",
        "    self.fc1 = nn.Linear(28*28,64)\n",
        "    \"\"\"\n",
        "    second layer takes input from the output of first fully connected layer\n",
        "    so the input to second layer is 64\n",
        "    \"\"\"\n",
        "    self.fc2 = nn.Linear(64,64)\n",
        "    self.fc3 = nn.Linear(64,64)\n",
        "    \"\"\"\n",
        "    we have ten classes (0 to 9) so for the final the number of output neurons\n",
        "    is equal to 10\n",
        "    \"\"\"\n",
        "    self.fc4 = nn.Linear(64,10)\n",
        "\n",
        "  def forward(self,x):\n",
        "    \"\"\"\n",
        "      Feed forward network\n",
        "    \"\"\"\n",
        "    \"\"\"\n",
        "      pass input to first layer and use Rectified Linear Unit for activation \n",
        "      function on the output of first layer.\n",
        "      \n",
        "    \"\"\"\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.relu(self.fc2(x))\n",
        "    x = F.relu(self.fc3(x))\n",
        "    x = self.fc4(x)\n",
        "\n",
        "    \"\"\"\n",
        "    Applies a softmax followed by a logarithm.\n",
        "\n",
        "    While mathematically equivalent to log(softmax(x)), doing these two\n",
        "    operations separately is slower, and numerically unstable. This function\n",
        "    uses an alternative formulation to compute the output and gradient correctly.\n",
        "\n",
        "    dim :  A dimension along which log_softmax will be computed.\n",
        "\n",
        "    \"\"\"\n",
        "    return F.log_softmax(x,dim =1)\n",
        "\n",
        "    \n",
        "\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-c5Aybm_hqzY"
      },
      "source": [
        "###Testing Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eLX2qumHbAES"
      },
      "source": [
        "net = Net()\n",
        "X= torch.rand((28,28)).view([1,28*28])\n",
        "\"\"\"\n",
        "X= torch.rand((28,28)).view([-1,28*28])\n",
        "use this for any input (dimension)\n",
        "\"\"\"\n",
        "output = net(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NBPwhK_Th_iL"
      },
      "source": [
        "Predictions - output\n",
        "\n",
        "* We didnt initialize weights randomly\n",
        "* grad_fn = Gradient Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "47ZC9r1UgXM-",
        "outputId": "5f9afdd2-16b2-4f58-b122-4cb06753bb69",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "output"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-2.3593, -2.3567, -2.2077, -2.2505, -2.2086, -2.3239, -2.4350, -2.2943,\n",
              "         -2.3475, -2.2662]], grad_fn=<LogSoftmaxBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    }
  ]
}